data_run <- read.table(file="data/run.txt", header=TRUE)
cor.test(data_run[,1],data_run[,2])
data_run_lemo <- data_run[data_run[,"drink" ]=="lemo",]
data_run_energy <- data_run[data_run[,"drink" ]=="energy",]
t.test(data_run_lemo[,1], data_run_lemo[,2],paired=TRUE)
# Is the same as
t.test(data_run_lemo[,1]-data_run_lemo[,2])
t.test(data_run_energy[,1]-data_run_energy[,2])
# C
data_run$dif <- data_run[,1]-data_run[,2]
# C
data_run$dif <- data_run[,1]-data_run[,2]
data_run_lemo <- data_run[data_run[,"drink" ]=="lemo",]
data_run_energy <- data_run[data_run[,"drink" ]=="energy",]
t.test(data_run_lemo$dif, data_run_energy$dif)
qqnorm(data_run_lemo$dif)
qqnorm(data_run_energy$dif) # Not really normal so other test
qqnorm(data_run_lemo$dif)
qqnorm(data_run_energy$dif) # Not really normal so other test
wilcox.test(data_run_lemo$dif, data_run_energy$dif)
ks.test(data_run_lemo$dif, data_run_energy$dif)
# Exercise 5
# A
data_chick <- chickwts
chick_meat <- subset(data_chick, feed == "meatmeal")
chick_sunf <- subset(data_chick, feed == "sunflower")
t.test(chick_meat$weight,chick_sunf$weight)
par(mfrow=c(1,2)) # set the plotting area into a 1*2 array
qqnorm(chick_meat$weight)
qqnorm(chick_sunf$weight) # Not really normal so:
wilcox.test(chick_meat$weight,chick_sunf$weight)
ks.test(chick_meat$weight,chick_sunf$weight)
chickaov <- lm(weight~feed, data = chickwts)
# performing one-way ANOVA
anova(chickaov)
#extracting more information
summary_table <- summary(chickaov)
summary_table$coefficients
chickaov <- lm(weight~feed, data = chickwts)
# performing one-way ANOVA
anova(chickaov)
#extracting more information
summary_table <- summary(chickaov)
summary_table$coefficients
View(data_chick)
n <- m <- 30
mu <- 180
nu <- 175
sd <- 5
B <- 1000
p <- numeric(B)
grid <- seq(175,185, by=0.25)
G <- length(grid)
fractions <- numeric(G)
for (grid_nu in 1:G){
p <- numeric(B)
for (b in 1:B){
x <- rnorm(n,mu,sd)
y <- rnorm(m,grid[grid_nu],sd)
p[b] <- t.test(x,y, var.equal = TRUE)[[3]]
}
fractions[grid_nu] <- mean(p<0.05)
}
plot(grid,fractions)
n <- m <- 100
mu <- 180
sd <- 5
fractions <- numeric(G)
for (grid_nu in 1:G){
p <- numeric(B)
for (b in 1:B){
x <- rnorm(n,mu,sd)
y <- rnorm(m,grid[grid_nu],sd)
p[b] <- t.test(x,y, var.equal = TRUE)[[3]]
}
fractions[grid_nu] <- mean(p<0.05)
}
plot(grid,fractions)
n <- m <- 30
mu <- 180
sd <- 15
fractions <- numeric(G)
for (grid_nu in 1:G){
p <- numeric(B)
for (b in 1:B){
x <- rnorm(n,mu,sd)
y <- rnorm(m,grid[grid_nu],sd)
p[b] <- t.test(x,y, var.equal = TRUE)[[3]]
}
fractions[grid_nu] <- mean(p<0.05)
}
plot(grid,fractions)
# Exercise 2
# A
n <- m <- 30
mu <- 180
nu <- 175
sd <- 5
grid <- seq(175,185, by=0.25)
power_function(grid,n,m,mu,sd){
B <- 1000
p <- numeric(B)
G <- length(grid)
fractions <- numeric(G)
for (grid_nu in 1:G){
p <- numeric(B)
for (b in 1:B){
x <- rnorm(n,mu,sd)
y <- rnorm(m,grid[grid_nu],sd)
p[b] <- t.test(x,y, var.equal = TRUE)[[3]]
}
fractions[grid_nu] <- mean(p<0.05)
}
return(fractions)
}
fractions <- power_function(grid,n,m,mu,sd)
power_function
power_function(grid,n,m,mu,sd) {
B <- 1000
p <- numeric(B)
G <- length(grid)
fractions <- numeric(G)
for (grid_nu in 1:G){
p <- numeric(B)
for (b in 1:B){
x <- rnorm(n,mu,sd)
y <- rnorm(m,grid[grid_nu],sd)
p[b] <- t.test(x,y, var.equal = TRUE)[[3]]
}
fractions[grid_nu] <- mean(p<0.05)
}
return(fractions)
}
fractions <- power_function(grid,n,m,mu,sd)
plot(grid,fractions)
par(mfrow=c(1,3))
n <- m <- 30
mu <- 180
nu <- 175
sd <- 5
grid <- seq(175,185, by=0.25)
power_function(grid,n,m,mu,sd) {
n <- m <- 30
mu <- 180
nu <- 175
sd <- 5
grid <- seq(175,185, by=0.25)
power_function<-function(grid,n,m,mu,sd) {
B <- 1000
p <- numeric(B)
G <- length(grid)
fractions <- numeric(G)
for (grid_nu in 1:G){
p <- numeric(B)
for (b in 1:B){
x <- rnorm(n,mu,sd)
y <- rnorm(m,grid[grid_nu],sd)
p[b] <- t.test(x,y, var.equal = TRUE)[[3]]
}
fractions[grid_nu] <- mean(p<0.05)
}
return(fractions)
}
fractions <- power_function(grid,n,m,mu,sd)
par(mfrow=c(1,3))
plot(grid,fractions)
n <- m <- 100
mu <- 180
sd <- 5
fractions <- power_function(grid,n,m,mu,sd)
plot(grid,fractions)
n <- m <- 30
mu <- 180
sd <- 15
fractions <- power_function(grid,n,m,mu,sd)
plot(grid,fractions)
n <- m <- 30
mu <- 180
nu <- 175
sd <- 5
grid <- seq(175,185, by=0.25)
power_function<-function(grid,n,m,mu,sd) {
B <- 1000
p <- numeric(B)
G <- length(grid)
fractions <- numeric(G)
for (grid_nu in 1:G){
p <- numeric(B)
for (b in 1:B){
x <- rnorm(n,mu,sd)
y <- rnorm(m,grid[grid_nu],sd)
p[b] <- t.test(x,y, var.equal = TRUE)[[3]]
}
fractions[grid_nu] <- mean(p<0.05)
}
return(fractions)
}
fractions1 <- power_function(grid,n,m,mu,sd)
n <- m <- 100
mu <- 180
sd <- 5
fractions2 <- power_function(grid,n,m,mu,sd)
n <- m <- 30
mu <- 180
sd <- 15
fractions3 <- power_function(grid,n,m,mu,sd)
par(mfrow=c(1,3))
plot(grid,fractions1)
plot(grid,fractions2)
plot(grid,fractions3)
install.packages("pander")
library(tidyverse)
library(rstudioapi)
library(pander)
panderOptions('round', 3)
panderOptions('keep.trailing.zeros', TRUE)
knitr::opts_chunk$set(echo = TRUE)
options(knitr.table.format = "latex")
setwd(dirname(getActiveDocumentContext()$path))
setwd(dirname(getActiveDocumentContext()$path))
library(tidyverse)
library(rstudioapi)
library(pander)
panderOptions('round', 3)
panderOptions('keep.trailing.zeros', TRUE)
knitr::opts_chunk$set(echo = TRUE)
options(knitr.table.format = "latex")
setwd(dirname(getActiveDocumentContext()$path))
plot(grid,fractions)
tinytex::install_tinytex()
install.packages('tinytex')
install.packages("tinytex")
library(tidyverse)
library(tidyverse)
library(rstudioapi)
library(pander)
panderOptions('round', 3)
panderOptions('keep.trailing.zeros', TRUE)
options(knitr.table.format = "latex")
setwd(dirname(getActiveDocumentContext()$path))
View(data)
library(tidyverse)
library(rstudioapi)
knitr::opts_chunk$set(echo = TRUE)
options(knitr.table.format = "latex")
setwd(dirname(getActiveDocumentContext()$path))
# round numbers to 4 digits
options(scipen = 1, digits = 4)
lambda <- seq(0.01, 0.1, 0.0005)
pvalues <- c()
t <- median(data_tele)
for (x in X){
B <- 1000
tstar <- numeric(B)
n <- length(data_tele)
for (i in 1:B){
xstar <- rexp(n,x)
tstar[i] <- median(xstar)
}
pl<-sum(tstar<t)/B
pr<-sum(tstar>t)/B
p<-2*min(pl,pr)
pl;pr;p
pvalues <- c(pvalues,p)
}
plot(lambda, pvalues)
plot(lambda, best_p)
plot(best_p)
best_p <- pvalues > 0.05
plot(best_p)
best_p
best_p <- which(pvalues > 0.05)
best_p
pvalues[best_p]
plot(lambda[best_p],pvalues[best_p])
pvalues[best_p]
lambda[best_p]
lambda <- seq(0.01, 0.1, 0.0005)
pvalues <- c()
t <- median(data_tele)
for (x in X){
B <- 1000
tstar <- numeric(B)
n <- length(data_tele)
for (i in 1:B){
xstar <- rexp(n,x)
tstar[i] <- median(xstar)
}
pl<-sum(tstar<t)/B
pr<-sum(tstar>t)/B
p<-2*min(pl,pr)
pl;pr;p
pvalues <- c(pvalues,p)
}
plot(lambda, pvalues)
best_p <- which(pvalues > 0.05)
lambda[best_p]
data<-read.table(file="data/telephone.txt",header=TRUE)
# remove zeros
data <- data %>%
filter(Bills > 0)
data_tele <- data$Bills
par(mfrow=c(1,3))
hist(data_tele)
qqnorm(data_tele)
boxplot(data_tele)
lambda <- seq(0.01, 0.1, 0.0005)
pvalues <- c()
t <- median(data_tele)
for (x in X){
B <- 1000
tstar <- numeric(B)
n <- length(data_tele)
for (i in 1:B){
xstar <- rexp(n,x)
tstar[i] <- median(xstar)
}
pl<-sum(tstar<t)/B
pr<-sum(tstar>t)/B
p<-2*min(pl,pr)
pl;pr;p
pvalues <- c(pvalues,p)
}
plot(lambda, pvalues)
best_p <- which(pvalues > 0.05)
lambda[best_p]
options(knitr.table.format = "latex")
library(tidyverse)
library(rstudioapi)
knitr::opts_chunk$set(echo = TRUE)
options(knitr.table.format = "latex")
setwd(dirname(getActiveDocumentContext()$path))
# round numbers to 4 digits
options(scipen = 1, digits = 4)
library(tidyverse)
library(rstudioapi)
knitr::opts_chunk$set(echo = TRUE)
options(knitr.table.format = "latex")
setwd(dirname(getActiveDocumentContext()$path))
library(tidyverse)
library(rstudioapi)
knitr::opts_chunk$set(echo = TRUE)
options(knitr.table.format = "latex")
setwd(dirname(getActiveDocumentContext()$path))
knitr::opts_chunk$set(echo = TRUE)
options(knitr.table.format = "latex")
setwd(dirname(getActiveDocumentContext()$path))
knitr::opts_chunk$set(echo = TRUE)
options(knitr.table.format = "latex")
setwd(dirname(getActiveDocumentContext()$path))
# Exercise 1
The data set birthweight.txt contains the birthweights of 188 newborn babies.  We are interested in finding the underlying (population) mean mu of birthweights.
**a)** Check normality of the data.  Compute a point estimate for mu.  Derive, assuming normality (irrespective of your conclusion about normality od the data), a bounded 90% confidence interval for mu.
To check normality for the data we use a qqplot, historgram, box plot and shapiro-wilks test.
```{r}
par(mfrow=c(1,3))
data=read.table(file="data/birthweight.txt",header=TRUE)
bw = data$birthweight
hist(bw)
qqnorm(bw)
boxplot(bw)
shapiro.test(bw)
```{r}
```{r}
par(mfrow=c(1,3))
data=read.table(file="data/birthweight.txt",header=TRUE)
bw = data$birthweight
hist(bw)
qqnorm(bw)
boxplot(bw)
shapiro.test(bw)
```{r}
```{r}
m = mean(bw)
```{r setup, include=FALSE}
library(tidyverse)
library(rstudioapi)
knitr::opts_chunk$set(echo = TRUE)
options(knitr.table.format = "latex")
setwd(dirname(getActiveDocumentContext()$path))
knitr::opts_chunk$set(echo = TRUE)
options(knitr.table.format = "latex")
setwd(dirname(getActiveDocumentContext()$path))
# Exercise 1
The data set birthweight.txt contains the birthweights of 188 newborn babies.  We are interested in finding the underlying (population) mean mu of birthweights.
**a)** Check normality of the data.  Compute a point estimate for mu.  Derive, assuming normality (irrespective of your conclusion about normality od the data), a bounded 90% confidence interval for mu.
To check normality for the data we use a qqplot, historgram, box plot and shapiro-wilks test.
```{r}
par(mfrow=c(1,3))
data=read.table(file="data/birthweight.txt",header=TRUE)
bw = data$birthweight
hist(bw)
qqnorm(bw)
boxplot(bw)
shapiro.test(bw)
```{r}
shapiro.test(bw)
boxplot(bw)
shapiro.test(bw)
```{r}
```{r}
m = mean(bw)
sd = sd(bw)
n = length(bw)
error = qnorm(0.95)*sd/sqrt(n)
ci = c(m-error, m+error)
m
ci
m = mean(bw)
sd = sd(bw)
n = length(bw)
error = qnorm(0.95)*sd/sqrt(n)
ci = c(m-error, m+error)
m
ci
**b)** An expert claims that the mean birthweight is bigger than 2800, verify this claim by using at-test.What is the outcome of the test if you take alpha = 0.1?  And other values of alpha?
A t-test is performed to verify the claim that the mean birthweight is bigger than 2800. The t-test shows a p-value of 0.014. This means that this claim is significant for an alpha of 0.1. The claim is significant for all alpha's above 0.014 and insignificant for alpha's below 0.014.
```{r}
t.test(bw, mu=2800, alternative = "greater", conf.level = 0.95)
```
**c)** In the R-output of the test from b), also a confidence interval is given, but why is it different from theconfidence interval found in a) and why is it one-sided?
The confidence interval interval is different because the one-sample t-test returns a 95% confidence interval while a 90% confidence interval is conducted in 1b). The confidence interval is one sided because the critical area of the weight distribution  is compared to a mean where it is greater than 2800, but not both greater and less than 2800.
# Exercise 2
We study the power function of the two-sample t-test (see Section 1.9 of Assignment 0). For n=m=30, mu=180, nu=175 and sd=5, generate 1000 samples x=rnorm(n,mu,sd) and y=rnorm(m,nu,sd), and record the 1000 p-values for testing H0: mu=nu. You can evaluate the power (at point nu=175) of this t-test as fraction of p-values that are smaller than 0.05.
**a)** Set n=m=30, mu=180 and sd=5. Calculate now the power of the t-test for every value of nu in the grid seq(175,185,by=0.25). Plot the power as a function of nu.
```{r}
n <- m <- 30
mu <- 180
nu <- 175
sd <- 5
grid <- seq(175,185, by=0.25)
power_function<-function(grid,n,m,mu,sd) {
B <- 1000
p <- numeric(B)
G <- length(grid)
fractions <- numeric(G)
for (grid_nu in 1:G){
p <- numeric(B)
for (b in 1:B){
x <- rnorm(n,mu,sd)
y <- rnorm(m,grid[grid_nu],sd)
p[b] <- t.test(x,y, var.equal = TRUE)[[3]]
}
fractions[grid_nu] <- mean(p<0.05)
}
return(fractions)
}
```{r}
fractions_A <- power_function(grid,n,m,mu,sd)
```{r}
```{r}
n <- m <- 100
for (i in 1:B){
xstar <- rexp(n,x)
tstar[i] <- median(xstar)
}
lambda <- seq(0.01, 0.1, 0.0005)
pvalues <- c()
t <- median(data_tele)
data<-read.table(file="data/telephone.txt",header=TRUE)
# remove zeros
data <- data %>%
filter(Bills > 0)
data_tele <- data$Bills
par(mfrow=c(1,3))
hist(data_tele)
qqnorm(data_tele)
boxplot(data_tele)
lambda <- seq(0.01, 0.1, 0.0005)
pvalues <- c()
t <- median(data_tele)
for (x in lambda){
B <- 1000
tstar <- numeric(B)
n <- length(data_tele)
for (i in 1:B){
xstar <- rexp(n,x)
tstar[i] <- median(xstar)
}
pl<-sum(tstar<t)/B
pr<-sum(tstar>t)/B
p<-2*min(pl,pr)
pl;pr;p
pvalues <- c(pvalues,p)
}
plot(lambda, pvalues)
best_p <- which(pvalues > 0.05)
lambda[best_p]
theoretical_median
max_index <- which.max(pvalues)
opt_Lambda <- lambda[max_index]
theoretical_mean = 1/opt_Lambda
theoretical_mean
theoretical_median = log(2)/opt_Lambda
theoretical_median
theoretical_var = ((1/opt_Lambda)^2 )/length(data_tele)
error = qnorm(0.975)*(theoretical_median/sqrt(length(data_tele)))
ci = c(theoretical_median - error, theoretical_median + error)
ci
library(tidyverse)
library(rstudioapi)
knitr::opts_chunk$set(echo = TRUE)
options(knitr.table.format = "latex")
setwd(dirname(getActiveDocumentContext()$path))
# round numbers to 4 digits
options(scipen = 1, digits = 4)
bill_bigeq40 <- sum(data_tele>=40)
bill_smal40 <- sum(data_tele<40)
binom.test(bill_bigeq40, length(data_tele),p=0.5)
binom.test(bill_smal40, length(data_tele),p=0.5)
bill_less10 <- sum(data_tele < 10)
bill_less10/length(data_tele)
