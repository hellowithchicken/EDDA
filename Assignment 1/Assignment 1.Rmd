---
title: "EDDA - Assignment 1 - Group 77"
subtitle: "Dante de Lang, Ignas Krikštaponis and Kamiel Gülpen"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
library(tidyverse)
library(rstudioapi)

knitr::opts_chunk$set(echo = TRUE)
options(knitr.table.format = "latex")
setwd(dirname(getActiveDocumentContext()$path))
```

# Exercise 1
The data set birthweight.txt contains the birthweights of 188 newborn babies.  We are interested in finding the underlying (population) mean mu of birthweights.

**a)** Check normality of the data.  Compute a point estimate for mu.  Derive, assuming normality (irrespective of your conclusion about normality od the data), a bounded 90% confidence interval for mu.


To check normality for the data we use a qqplot, historgram, box plot and shapiro-wilks test. 
```{r}
par(mfrow=c(1,3))
data=read.table(file="data/birthweight.txt",header=TRUE)

bw = data$birthweight
hist(bw)
qqnorm(bw)
boxplot(bw)
shapiro.test(bw)

```
The graphical methods show that the data is normal. The Shapiro-Wilk test reinforces this assumption as it shows a p-value of 0.8995, meaning that the H0 is not rejected and therefore the data is normal. Furthermore, a point estimate for mu is conducted along side a 90% confidence interval.

```{r}
m = mean(bw)
sd = sd(bw)
n = length(bw)
error = qnorm(0.95)*sd/sqrt(n)
ci = c(m-error, m+error)
m
ci
```


**b)** An expert claims that the mean birthweight is bigger than 2800, verify this claim by using at-test.What is the outcome of the test if you take alpha = 0.1?  And other values of alpha?

A t-test is performed to verify the claim that the mean birthweight is bigger than 2800. The t-test shows a p-value of 0.014. This means that this claim is significant for an alpha of 0.1. The claim is significant for all alpha's above 0.014 and insignificant for alpha's below 0.014.
```{r}
t.test(bw, mu=2800, alternative = "greater", conf.level = 0.95)
```

**c)** In the R-output of the test from b), also a confidence interval is given, but why is it different from theconfidence interval found in a) and why is it one-sided?


The confidence interval interval is different because the one-sample t-test returns a 95% confidence interval while a 90% confidence interval is conducted in 1b). The confidence interval is one sided because the critical area of the weight distribution  is compared to a mean where it is greater than 2800, but not both greater and less than 2800.


# Exercise 2
We study the power function of the two-sample t-test (see Section 1.9 of Assignment 0). For n=m=30, mu=180, nu=175 and sd=5, generate 1000 samples x=rnorm(n,mu,sd) and y=rnorm(m,nu,sd), and record the 1000 p-values for testing H0: mu=nu. You can evaluate the power (at point nu=175) of this t-test as fraction of p-values that are smaller than 0.05.

**a)** Set n=m=30, mu=180 and sd=5. Calculate now the power of the t-test for every value of nu in the grid seq(175,185,by=0.25). Plot the power as a function of nu.

```{r}
n <- m <- 30
mu <- 180
nu <- 175
sd <- 5
grid <- seq(175,185, by=0.25)

power_function<-function(grid,n,m,mu,sd) {
  B <- 1000
  p <- numeric(B)
  G <- length(grid)
  fractions <- numeric(G)
  for (grid_nu in 1:G){
    p <- numeric(B)
    for (b in 1:B){
      x <- rnorm(n,mu,sd)
      y <- rnorm(m,grid[grid_nu],sd)
      p[b] <- t.test(x,y, var.equal = TRUE)[[3]]
    }
    fractions[grid_nu] <- mean(p<0.05)
  }
  return(fractions)
}

fractions_A <- power_function(grid,n,m,mu,sd)

```
**b)** Set n=m=100, mu=180 and sd=5. Repeat the preceding exercise. Add the plot to the preceding plot.

```{r}
n <- m <- 100
mu <- 180
sd <- 5

fractions_B <- power_function(grid,n,m,mu,sd)
```

**c)** Set n=m=30, mu=180 and sd=15. Repeat the preceding exercise.

```{r}
n <- m <- 30
mu <- 180
sd <- 15

fractions_C <- power_function(grid,n,m,mu,sd)
par(mfrow=c(1,3))
plot(grid,fractions_A)
plot(grid,fractions_B)
plot(grid,fractions_C)
```

**d)** Explain your findings.

More data points seems to have an influence on the narrowness of the plot. Furthermore, a bigger standard deviations gives a more wider distribution of fractions as presented in the plot of C with lower fractions. This can be explained by the fact that a higher standard deviations gives a higher uncertainty which results in a lower amount of fractions with a p-value below 0.05.

# Exercise 3
A telecommunication company has entered the market for mobile phones in a new country. The company's marketing manager conducts a survey of 200 new subscribers for mobile phones. The results of the survey are in the data set telephone.txt, which contains the first month bills X_1,...,X_200, in euros.

**a)** Make an appropriate plot of this data set. What marketing advice(s) would you give to the marketing manager? Are there any inconsistencies in the data? If so, try to fix these.

```{r}
data<-read.table(file="data/telephone.txt",header=TRUE)

# remove zeros
data <- data %>% 
  filter(Bills > 0)

data_tele <- data$Bills
par(mfrow=c(1,3))
hist(data_tele)
qqnorm(data_tele)
boxplot(data_tele)

```

From the survey it seems that there are two distinct peaks,therefore it would be good to run two separate marketing campaigns: a "premium" service campaign for customers who are willing to spend more and a campaign aimed at savers, usually people who use pre-paid services, - establishing a separate "cheaper" brand would be a good strategy here.

The survey data also encompassed people who did not have any spendings on the phone bills, therefore they were removed from the analysis.

**b)** By using a bootstrap test with the test statistic T = median(X_1,....,X_200), test whether the data telephone.txt stems from the exponential distribution Exp(lambda) with some lambda from [0.01, 0.1].

```{r}
lambda <- seq(0.01, 0.1, 0.0005)
pvalues <- c()
t <- median(data_tele)
for (x in lambda){
  B <- 1000
  tstar <- numeric(B)
  n <- length(data_tele)
  
  for (i in 1:B){
    xstar <- rexp(n,x)
    tstar[i] <- median(xstar)
  }
  pl<-sum(tstar<t)/B
  pr<-sum(tstar>t)/B
  p<-2*min(pl,pr)
  pl;pr;p
  pvalues <- c(pvalues,p)
}
plot(lambda, pvalues)

best_p <- which(pvalues > 0.05)
lambda[best_p]
```
The figure above shows the p-values for different lambda values. There can be concluded that the data stems from a exponential distribution for the lambda values 0.02 till 0.029.

**c)** Construct a 95% bootstrap confidence interval for the population median of the sample.
```{r}
B <- 1000
T1 <- median(data_tele)
Tstar <- numeric(B)
for (i in 1:B){
  Xstar <- sample(data_tele,replace=TRUE)
  Tstar[i] <- median(Xstar)
}
Tstar25 <- quantile(Tstar,0.025)
Tstar975 <- quantile(Tstar, 0.975)

T1
c(2*T1-Tstar975, 2*T1-Tstar25)

```
The 95% bootstrap confidence interval of the median is [16.43, 36,576], with 28.905 as median.


**d)** Assuming X_1,....,X_n ~ Exp(lambda) and using the central limit theorem for the sample mean, estimate lambda and construct again a 95% confidence interval for the population median. Comment on your findings.
 
```{r}
max_index <- which.max(pvalues)

<<<<<<< HEAD
opt_Lambda <- lambda[max_index]
=======
opt_Lambda <- X[max_index]

theoretical_mean = 1/opt_Lambda
theoretical_median = log(2)/opt_Lambda
theoretical_var = ((1/opt_Lambda)^2 )/length(data_tele)
error = qnorm(0.975)*(theoretical_median/sqrt(length(data_tele)))
ci = c(theoretical_median - error, theoretical_median + error)
ci

>>>>>>> a0b2f998bdf856dce967849feb47b8363f22dd1d
```
The variable opt_Lambda is the optimal lambda value with the highest P-value.

**e)** Using an appropriate test, test the null hypothesis that the median bill is bigger or equal to 40 euro against the alternative that the median bill is smaller than 40 euro. Next, design and perform a test to check whether the fraction of the bills less than 10 euro is less than 25%.
```{r}
bill_bigeq40 <- sum(data_tele>=40)
bill_smal40 <- sum(data_tele<40)

binom.test(bill_bigeq40, length(data_tele),p=0.5)
binom.test(bill_smal40, length(data_tele),p=0.5)

bill_less10 <- sum(data_tele < 10)
bill_less10/length(data_tele)
```


# Exercise 4
To study the effect of energy drink a sample of 24 high school pupils were randomized to drinking either a softdrink or an energy drink after running for 60 meters. After half an hour they were asked to run again. For both sprints they were asked to sprint as fast they could, and the sprinting time was measured. The data is given in the file run.txt. [Courtesy class 5E, Stedelijk Gymnasium Leiden, 2010.]

**a)** Disregarding the type of drink, test whether the run times before drink and after are correlated.

```{r}
data <- read.table(file="data/run.txt",header=TRUE)
cor(data$before, data$after)
```

Run times before and after the drink seem to be positively correlated.

**b)** Test separately, for both the softdrink and the energy drink conditions, whether there is a difference in speed in the two running tasks.

```{r}
# calculate differences
data <- data %>% 
  mutate(diff = before - after)

# filter for lemo

lemo <- data %>% 
  filter(drink == "lemo")

t.test(lemo$before, lemo$after, paired = TRUE)

# filter for energy

energy <- data %>% 
  filter(drink == "energy")

t.test(energy$before, energy$after, paired = TRUE)
```

For both energy and soft-drink groups there does not seem to be a significant difference in running times.

**c)** For each pupil compute the time difference between the two running tasks. Test whether these time differences are effected by the type of drink.

```{r}

# perform t-test

t.test(lemo$diff, energy$diff)

```
The p-value is > 0.05 therefore the means of the two populations are not significantly different.

**d)** Can you think of a plausible objection to the design of the experiment in b) if the main aim was to test whether drinking the energy drink speeds up the running? Is there a similar objection to the design of the experiment in c)? Comment on all your findings in this exercise.

In both experiments the participants were asked to run on the same day. This could strongly influence the outcomes in data. Therefore, the setup was certainly not ideal to check the influence of both drinks. 

# Exercise 5

**a)** Test whether the distributions of the chicken weights for meatmeal and sunflower groups are different by performing three tests: the two samples t-test (argue whether the data are paired or not), the Mann-Whitney test and the Kolmogorov-Smirnov test. Comment on your findings.

```{r}
# filter for meatmeal

meatmeal <- chickwts %>% 
  filter(feed == "meatmeal") %>% 
  select(weight)

# filter for sunflower

sunflower <- chickwts %>% 
  filter(feed == "sunflower") %>% 
  select(weight)

# check for data normality

par(mfrow=c(1,2))
qqnorm(meatmeal$weight)
qqnorm(sunflower$weight)

# perform t-test, the data is not paired

t.test(meatmeal, sunflower)

# Mann-Whitney test

wilcox.test(meatmeal$weight, sunflower$weight)

# Kolmogorov-Smirnov test

ks.test(meatmeal$weight, sunflower$weight)

```

Data in chickwts is not paired as the "treatment" of different feed was applied to different newly-hatched chicks not the same chick. From t-test we can see that the p-values <0.05, therefore the means between the two groups are significantly different. From Mann-Whitney test we can see that p-value is >0.05 therefore we can not conclude that the medians of the two datasets are different. From Kolgomorov-Smirnov test we can not conclude that the means are different.

**b)**Conduct a one-way ANOVA to determine whether the type of feed supplement has an effect on the weight of the chicks. Give the estimated chick weights for each of the six feed supplements. What is the best feed supplement?

```{r}
chickaov <- lm(weight~feed, data = chickwts)
# performing one-way ANOVA
anova(chickaov)
#extracting more information
summary_table <- summary(chickaov)
knitr::kable(data.frame(summary_table$coefficients), "latex")
```
From the results of one-way ANOVA we can see that the p-values is <0.05 therefore we can conclude that the means between all of the feed varieties are significantly different. 
From summary statistics it seems that "sunflower" feed is the feed resulting in highest weight. therefore it is the best.

**c)**Check the ANOVA model assumptions by using relevant diagnostic tools.

```{r}
# check for normality
qqnorm(chickaov$residuals)
# check if the variances are equal
chickwts %>% 
  group_by(feed) %>% 
  summarise(variance = var(weight))
```
From qqplot assumption of normality holds. However the assumption of equal variances does not hold.

**d)** Does the Kruskal-Wallis test arrive at the same conclusion about the effect of feed supplement as the test in b)? Explain possible differences between conclusions of the Kruskal-Wallis and ANOVA tests.

```{r}
kruskal.test(weight~feed, data = chickwts)
```

With Kruskal-Wallis test we arrive to the same conclusion as with ANOVA. 

